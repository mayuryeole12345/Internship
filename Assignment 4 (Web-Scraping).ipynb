{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1. Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "#get the url\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>\"LooLoo Kids\"</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                  Name                          Artist  \\\n",
       "0   1.      Baby Shark Dance  Pinkfong Kids' Songs & Stories   \n",
       "1   2.             Despacito                      Luis Fonsi   \n",
       "2   3.  Johny Johny Yes Papa                   \"LooLoo Kids\"   \n",
       "3   4.          Shape of You                      Ed Sheeran   \n",
       "4   5.         See You Again                     Wiz Khalifa   \n",
       "\n",
       "        Upload_date Views  \n",
       "0     June 17, 2016  9.04  \n",
       "1  January 12, 2017  7.46  \n",
       "2   October 8, 2016  5.58  \n",
       "3  January 30, 2017  5.40  \n",
       "4     April 6, 2015  5.19  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping Rank\n",
    "rank = driver.find_elements_by_xpath(\"//td[@align='center']\")[:15]\n",
    "for i in rank:       \n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)        \n",
    "\n",
    "time.sleep(3)        \n",
    "# scraping Name\n",
    "name = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//a\")[:20]\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "\n",
    "time.sleep(3)        \n",
    "# scraping Artist\n",
    "artist = driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']//a\")[:20]\n",
    "for i in artist:\n",
    "    if i.text is None :\n",
    "        Artist.append(\"--\") \n",
    "    else:\n",
    "        Artist.append(i.text)        \n",
    "        \n",
    "time.sleep(3)\n",
    "# scraping Upload_date\n",
    "date = driver.find_elements_by_xpath(\"//td[@align='right']\")[:5]\n",
    "for i in date:       \n",
    "    if i.text is None :\n",
    "        Upload_date.append(\"--\") \n",
    "    else:\n",
    "        Upload_date.append(i.text)        \n",
    "\n",
    "time.sleep(3)        \n",
    "# scraping Views\n",
    "view = driver.find_elements_by_xpath(\"//td[@align='center']\")[:15]\n",
    "for i in view:       \n",
    "        if i.text is None:\n",
    "            Views.append(\"--\")\n",
    "        else:\n",
    "            Views.append(i.text) \n",
    "            \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Rank\":Rank[0::3],\"Name\":Name[0::4],\"Artist\":Artist[2::4],\"Upload_date\":Upload_date,\"Views\":Views[1::3]})\n",
    "df.head()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2. Scrape the details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(4)\n",
    "\n",
    "#get the url\n",
    "url = \"https://www.bcci.tv/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking the options\n",
    "options=driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\")\n",
    "options.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#clicking the fixtures\n",
    "fixtures=driver.find_element_by_xpath(\"//a[@class='navigation__link navigation__link--in-drop-down']\")\n",
    "fixtures.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list for scraping data\n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "# scraping match title\n",
    "title = driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in title:       \n",
    "    if i.text is None :\n",
    "        Match_title.append(\"--\") \n",
    "    else:\n",
    "        Match_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25</td>\n",
       "      <td>AUGUST</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10</td>\n",
       "      <td>SEPTEMBER</td>\n",
       "      <td>Friday</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_title                Series                     Place Date      Month  \\\n",
       "0    1st Test  ENGLAND V INDIA 2021  Trent Bridge, Nottingham   04     AUGUST   \n",
       "1    2nd Test  ENGLAND V INDIA 2021            Lord's, London   12     AUGUST   \n",
       "2    3rd Test  ENGLAND V INDIA 2021         Headingley, Leeds   25     AUGUST   \n",
       "3    4th Test  ENGLAND V INDIA 2021          The Oval, London   02  SEPTEMBER   \n",
       "4    5th Test  ENGLAND V INDIA 2021  Old Trafford, Manchester   10  SEPTEMBER   \n",
       "\n",
       "         Day       Time  \n",
       "0  Wednesday  15:30 IST  \n",
       "1   Thursday  15:30 IST  \n",
       "2  Wednesday  15:30 IST  \n",
       "3   Thursday  15:30 IST  \n",
       "4     Friday  15:30 IST  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping series\n",
    "series = driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\")\n",
    "for i in series:       \n",
    "    if i.text is None :\n",
    "        Series.append(\"--\") \n",
    "    else:\n",
    "        Series.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "# scraping Place\n",
    "place = driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']//span\")\n",
    "for i in place:       \n",
    "    if i.text is None :\n",
    "        Place.append(\"--\") \n",
    "    else:\n",
    "        Place.append(i.text)  \n",
    "        \n",
    "time.sleep(3)\n",
    "# scraping Date\n",
    "date = driver.find_elements_by_xpath(\"//span[@class='fixture__date']\")\n",
    "for i in date:       \n",
    "    if i.text is None :\n",
    "        Date.append(\"--\") \n",
    "    else:\n",
    "        Date.append(i.text)\n",
    "        \n",
    "time.sleep(3)\n",
    "#creating empty list for month\n",
    "Month=[]\n",
    "# scraping Month\n",
    "month = driver.find_elements_by_xpath(\"//span[@class='fixture__month']\")\n",
    "for i in month:       \n",
    "    if i.text is None :\n",
    "        Month.append(\"--\") \n",
    "    else:\n",
    "        Month.append(i.text)      #optional scraping for Month\n",
    "        \n",
    "time.sleep(3)\n",
    "#creating empty list for day\n",
    "Day=[]\n",
    "# scraping Day\n",
    "day = driver.find_elements_by_xpath(\"//span[@class='fixture__day']\")\n",
    "for i in day:       \n",
    "    if i.text is None :\n",
    "        Day.append(\"--\") \n",
    "    else:\n",
    "        Day.append(i.text)      #optional scraping of Day  \n",
    "        \n",
    "time.sleep(3)\n",
    "# scraping Time\n",
    "time = driver.find_elements_by_xpath(\"//span[@class='fixture__time']\")\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Time.append(\"--\") \n",
    "    else:\n",
    "        Time.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Match_title\":Match_title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Month\":Month,\"Day\":Day,\"Time\":Time})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0      ElementNotVisibleException   \n",
       "1   ElementNotSelectableException   \n",
       "2          NoSuchElementException   \n",
       "3            NoSuchFrameException   \n",
       "4         NoAlertPresentException   \n",
       "5           NoSuchWindowException   \n",
       "6  StaleElementReferenceException   \n",
       "7        SessionNotFoundException   \n",
       "8                TimeoutException   \n",
       "9              WebDriverException   \n",
       "\n",
       "                                         Description  \n",
       "0  This type of Selenium exception occurs when an...  \n",
       "1  This Selenium exception occurs when an element...  \n",
       "2  This Exception occurs if an element could not ...  \n",
       "3  This Exception occurs if the frame target to b...  \n",
       "4  This Exception occurs when you switch to no pr...  \n",
       "5  This Exception occurs if the window target to ...  \n",
       "6  This Selenium exception occurs happens when th...  \n",
       "7  The WebDriver is acting after you quit the bro...  \n",
       "8  Thrown when there is not enough time for a com...  \n",
       "9  This Exception takes place when the WebDriver ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.guru99.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'selenium'\n",
    "selenium=driver.find_element_by_xpath(\"/html/body/div[2]/section[4]/div/div/div/div/div/div/div/div[1]/div/ul[1]/li[3]\")\n",
    "selenium.click()\n",
    "\n",
    "# clicking the 'exception handling'\n",
    "tutorial=driver.find_element_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div/div/div/div/div/div/div[2]/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "tutorial.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Name=[]\n",
    "Description=[]\n",
    "\n",
    "# scraping name\n",
    "name = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//td\")\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "\n",
    "# scraping Description\n",
    "desc = driver.find_elements_by_xpath(\"//table[@class='table table-striped']//td\")\n",
    "for i in desc:       \n",
    "        if i.text is None :\n",
    "            Description.append(\"--\")\n",
    "        else:\n",
    "            Description.append(i.text)\n",
    "            \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name[2::2],\"Description\":Description[3::2]})\n",
    "df.head(10)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4. Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"http://statisticstimes.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'economy'\n",
    "economy=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n",
    "economy.click()\n",
    "\n",
    "# clicking the 'dropdown button'\n",
    "dropdown=driver.find_element_by_xpath(\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "dropdown.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDSP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_18_19</th>\n",
       "      <th>GDP_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank           State GDSP_19_20 GSDP_18_19 Share_18_19 GDP_billion\n",
       "0    1     Maharashtra          -  2,632,792      13.94%     399.921\n",
       "1    2      Tamil Nadu  1,845,853  1,630,208       8.63%     247.629\n",
       "2    3   Uttar Pradesh  1,687,818  1,584,764       8.39%     240.726\n",
       "3    4         Gujarat          -  1,502,899       7.96%     228.290\n",
       "4    5       Karnataka  1,631,977  1,493,127       7.91%     226.806\n",
       "5    6     West Bengal  1,253,832  1,089,898       5.77%     165.556\n",
       "6    7       Rajasthan  1,020,989    942,586       4.99%     143.179\n",
       "7    8  Andhra Pradesh    972,782    862,957       4.57%     131.083\n",
       "8    9       Telangana    969,604    861,031       4.56%     130.791\n",
       "9   10  Madhya Pradesh    906,672    809,592       4.29%     122.977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clicking the 'statewise GDP of India'\n",
    "GDP_of_India=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "GDP_of_India.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Rank=[]\n",
    "State=[]\n",
    "GDSP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "Share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "# scraping rank\n",
    "rank = driver.find_elements_by_xpath(\"//td[@class='data1']\")[:33]\n",
    "for i in rank:       \n",
    "    if i.text is None :\n",
    "        Rank.append(\"--\") \n",
    "    else:\n",
    "        Rank.append(i.text)\n",
    "                \n",
    "# scraping state\n",
    "state = driver.find_elements_by_xpath(\"//td[@class='name']\")[:33]\n",
    "for i in state:       \n",
    "    if i.text is None :\n",
    "        State.append(\"--\") \n",
    "    else:\n",
    "        State.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (19-20)\n",
    "GSDP = driver.find_elements_by_xpath(\"//td[@class='data']\")[:165]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GDSP_19_20.append(\"--\") \n",
    "    else:\n",
    "        GDSP_19_20.append(i.text)\n",
    "                \n",
    "# scraping GSDP at current price (18-19)\n",
    "GSDP = driver.find_elements_by_xpath(\"//td[@class='data sorting_1']\")[:33]\n",
    "for i in GSDP:       \n",
    "    if i.text is None :\n",
    "        GSDP_18_19.append(\"--\") \n",
    "    else:\n",
    "        GSDP_18_19.append(i.text)\n",
    "                \n",
    "# scraping Share(18-19)\n",
    "share = driver.find_elements_by_xpath(\"//td[@class='data']\")[:165]\n",
    "for i in share:       \n",
    "    if i.text is None :\n",
    "        Share_18_19.append(\"--\") \n",
    "    else:\n",
    "        Share_18_19.append(i.text)\n",
    "                \n",
    "# scraping GDP($ billion)\n",
    "GDP = driver.find_elements_by_xpath(\"//td[@class='data']\")[:165]\n",
    "for i in GDP:\n",
    "    if i.text is None :\n",
    "            GDP_billion.append(\"--\") \n",
    "    else:\n",
    "        GDP_billion.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GDSP_19_20\":GDSP_19_20[::5],\"GSDP_18_19\":GSDP_18_19,\"Share_18_19\":Share_18_19[1::5],\"GDP_billion\":GDP_billion[2::5]})\n",
    "df.head(10)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 5. Scrape the details of trending repositories on Github.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple / swift-algorithms</td>\n",
       "      <td>Commonly used sequence and collection algorith...</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SJang1 / korea-covid-19-remaining-vaccine-macro</td>\n",
       "      <td>잔여백신 조회 및 예약 매크로</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataease / dataease</td>\n",
       "      <td>人人可用的开源数据可视化分析工具。</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google / googletest</td>\n",
       "      <td>GoogleTest - Google Testing and Mocking Framework</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>myspaghetti / macos-virtualbox</td>\n",
       "      <td>Push-button installer of macOS Catalina, Mojav...</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tailscale / tailscale</td>\n",
       "      <td>The easiest, most secure way to use WireGuard ...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>electron / electron</td>\n",
       "      <td>Build cross-platform desktop apps with JavaScr...</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Satsuoni / widevine-l3-guesser</td>\n",
       "      <td>decompiled pegasus_spyware</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jonathandata1 / pegasus_spyware</td>\n",
       "      <td>50+ mini web projects using HTML, CSS &amp; JS</td>\n",
       "      <td>Smali</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Repository_title  \\\n",
       "0                         apple / swift-algorithms   \n",
       "1                      freeCodeCamp / freeCodeCamp   \n",
       "2  SJang1 / korea-covid-19-remaining-vaccine-macro   \n",
       "3                              dataease / dataease   \n",
       "4                              google / googletest   \n",
       "5                   myspaghetti / macos-virtualbox   \n",
       "6                            tailscale / tailscale   \n",
       "7                              electron / electron   \n",
       "8                   Satsuoni / widevine-l3-guesser   \n",
       "9                  jonathandata1 / pegasus_spyware   \n",
       "\n",
       "                              Repository_description Language_used  \n",
       "0  Commonly used sequence and collection algorith...         Swift  \n",
       "1  freeCodeCamp.org's open-source codebase and cu...    JavaScript  \n",
       "2                                   잔여백신 조회 및 예약 매크로        Python  \n",
       "3                                  人人可用的开源数据可视化分析工具。          Java  \n",
       "4  GoogleTest - Google Testing and Mocking Framework           C++  \n",
       "5  Push-button installer of macOS Catalina, Mojav...         Shell  \n",
       "6  The easiest, most secure way to use WireGuard ...            Go  \n",
       "7  Build cross-platform desktop apps with JavaScr...           C++  \n",
       "8                         decompiled pegasus_spyware             C  \n",
       "9         50+ mini web projects using HTML, CSS & JS         Smali  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'explore'\n",
    "explore=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "explore.click()\n",
    "\n",
    "# clicking the 'trending'\n",
    "trending=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul[2]/li[3]/a\")\n",
    "trending.click()\n",
    "\n",
    "#creating empty list for scraping the data\n",
    "Repository_title=[]\n",
    "Repository_description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "\n",
    "# scraping Repository_title\n",
    "repo_title = driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\")[:22]\n",
    "for i in repo_title:       \n",
    "    if i.text is None :\n",
    "        Repository_title.append(\"--\") \n",
    "    else:\n",
    "        Repository_title.append(i.text)\n",
    "                        \n",
    "# scraping Repository_description\n",
    "repo_desc = driver.find_elements_by_xpath(\"//p[@class='col-9 color-text-secondary my-1 pr-4']\")[:22]\n",
    "for i in repo_desc:       \n",
    "    if i.text is None :\n",
    "        Repository_description.append(\"--\") \n",
    "    else:\n",
    "        Repository_description.append(i.text)\n",
    "            \n",
    "# scraping Language_used\n",
    "lang = driver.find_elements_by_xpath(\"//span[@itemprop='programmingLanguage']\")\n",
    "for i in lang:       \n",
    "    if i.text is None :\n",
    "        Language_used.append(\"--\") \n",
    "    else:\n",
    "        Language_used.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Repository_title\":Repository_title,\"Repository_description\":Repository_description,\"Language_used\":Language_used})\n",
    "df.head(10)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath('//h1[@class=\"h3 lh-condensed\"]//a')]\n",
    "for url in urls[0:22]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        count=driver.find_element_by_xpath('/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[4]/div/h2/a/span')\n",
    "        Contributors_count.append(count.text)\n",
    "    except NoSuchElementException :\n",
    "        Contributors_count.append(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 6. Scrape the details of top 100 songs on billboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_name</th>\n",
       "      <th>Artist_name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Build A Bitch</td>\n",
       "      <td>Bella Poarch</td>\n",
       "      <td>84</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>30</td>\n",
       "      <td>Pop Smoke Featuring Bizzy Banks</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>You Should Probably Leave</td>\n",
       "      <td>Chris Stapleton</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jealousy, Jealousy</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>87</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cold Beer Calling My Name</td>\n",
       "      <td>Jameson Rodgers Featuring Luke Combs</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song_name                           Artist_name  \\\n",
       "0                      Butter                                   BTS   \n",
       "1                    Good 4 U                        Olivia Rodrigo   \n",
       "2                  Levitating             Dua Lipa Featuring DaBaby   \n",
       "3                        Stay         The Kid LAROI & Justin Bieber   \n",
       "4                Kiss Me More                Doja Cat Featuring SZA   \n",
       "..                        ...                                   ...   \n",
       "95              Build A Bitch                          Bella Poarch   \n",
       "96                         30       Pop Smoke Featuring Bizzy Banks   \n",
       "97  You Should Probably Leave                       Chris Stapleton   \n",
       "98         Jealousy, Jealousy                        Olivia Rodrigo   \n",
       "99  Cold Beer Calling My Name  Jameson Rodgers Featuring Luke Combs   \n",
       "\n",
       "   Last_week_rank Peak_rank Weeks_on_board  \n",
       "0               7         1              9  \n",
       "1               2         1             10  \n",
       "2               4         2             42  \n",
       "3               3         3              2  \n",
       "4               5         3             15  \n",
       "..            ...       ...            ...  \n",
       "95             84        56             10  \n",
       "96              -        97              1  \n",
       "97             91        90              3  \n",
       "98             87        24              9  \n",
       "99             95        95              3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.billboard.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the chart\n",
    "chart=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]\")\n",
    "chart.click()\n",
    "\n",
    "# clicking the view chart\n",
    "hot100=driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[1]/a/div[2]/div[2]/div[1]\")\n",
    "hot100.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]\n",
    "\n",
    "# scraping Song name\n",
    "song = driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "for i in song:       \n",
    "    if i.text is None :\n",
    "        Song_name.append(\"--\") \n",
    "    else:\n",
    "        Song_name.append(i.text)         \n",
    "\n",
    "# scraping Artist name\n",
    "artist = driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "for i in artist:       \n",
    "    if i.text is None :\n",
    "        Artist_name.append(\"--\") \n",
    "    else:\n",
    "        Artist_name.append(i.text) \n",
    "        \n",
    "# scraping last week rank\n",
    "lw_rank = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "for i in lw_rank:       \n",
    "    if i.text is None :\n",
    "        Last_week_rank.append(\"--\") \n",
    "    else:\n",
    "        Last_week_rank.append(i.text)  \n",
    "\n",
    "# scraping peak rank\n",
    "peak = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "for i in peak:       \n",
    "    if i.text is None :\n",
    "        Peak_rank.append(\"--\") \n",
    "    else:\n",
    "        Peak_rank.append(i.text)    \n",
    "\n",
    "# scraping Weeks_on_board\n",
    "on_board = driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "for i in on_board:       \n",
    "    if i.text is None :\n",
    "        Weeks_on_board.append(\"--\")\n",
    "    else:\n",
    "        Weeks_on_board.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Song_name\":Song_name,\"Artist_name\":Artist_name,\"Last_week_rank\":Last_week_rank,\"Peak_rank\":Peak_rank,\"Weeks_on_board\":Weeks_on_board})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 7. Scrape the details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Director</td>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name                  Designation  \\\n",
       "0                           Aakash Harit                   HR Manager   \n",
       "1                   Data Science Network            Company Recruiter   \n",
       "2                   shravan Kumar Gaddam                   Company HR   \n",
       "3          Shore Infotech India Pvt. Ltd            Company Recruiter   \n",
       "4               MARSIAN Technologies LLP                  Founder CEO   \n",
       "5               MARSIAN Technologies LLP  Recruitment Lead Consultant   \n",
       "6                           Anik Agrawal            Programme Manager   \n",
       "7  Enerlytics Software Solutions Pvt Ltd             HR Administrator   \n",
       "8                           subhas patel                     Director   \n",
       "9                        LibraryXProject               Human Resource   \n",
       "\n",
       "                                 Company  \\\n",
       "0                           Aakash Harit   \n",
       "1                   Data Science Network   \n",
       "2                   shravan Kumar Gaddam   \n",
       "3          Shore Infotech India Pvt. Ltd   \n",
       "4               MARSIAN Technologies LLP   \n",
       "5               MARSIAN Technologies LLP   \n",
       "6                           Anik Agrawal   \n",
       "7  Enerlytics Software Solutions Pvt Ltd   \n",
       "8                           subhas patel   \n",
       "9                        LibraryXProject   \n",
       "\n",
       "                                Skills_they_hire_for                  Location  \n",
       "0  Classic ASP Developer, Internet Marketing Prof...                     Delhi  \n",
       "1  .Net, Java, Data Science, Linux Administration...  Hyderabad / Secunderabad  \n",
       "2  Data Science, Artificial Intelligence, Machine...                      Pune  \n",
       "3  Mean Stack, javascript, angularjs, mongodb, We...                 Ahmedabad  \n",
       "4  Hadoop, Spark, Digital Strategy, Data Architec...             UK - (london)  \n",
       "5  Analytics, Business Intelligence, Business Ana...         Vadodara / Baroda  \n",
       "6                                       Data Science                   Chennai  \n",
       "7  Machine Learning, algorithms, Go Getter, Compu...                Trivandrum  \n",
       "8  Technical Training, Software Development, Pres...                    Indore  \n",
       "9  Software Development, It Sales, Account Manage...     Bengaluru / Bangalore  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.naukri.com/hr-recruiters-consultants\"\n",
    "driver.get(url)\n",
    "\n",
    "# entering “Data Analyst” in “Skill,Designations,Companies” field.\n",
    "search_field=driver.find_element_by_xpath(\"//input[@class='sugInp']\") #job search bar\n",
    "search_field.send_keys(\"Data Science\")\n",
    "\n",
    "# clicking the search button\n",
    "search_button=driver.find_element_by_id(\"qsbFormBtn\")\n",
    "search_button.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills_they_hire_for=[]\n",
    "Location=[]\n",
    "\n",
    "#scraping the job-titles\n",
    "title=driver.find_elements_by_xpath(\"//p[@class='highlightable']//a\")[:48]\n",
    "for i in title:\n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "               \n",
    "#scraping the Designation\n",
    "deg=driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\")[:48]\n",
    "for i in deg:\n",
    "    if i.text is None :\n",
    "        Designation.append(\"--\") \n",
    "    else:\n",
    "        Designation.append(i.text)\n",
    "               \n",
    "#scraping the Company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='ellipsis']\")[:48]\n",
    "for i in comp:\n",
    "    if i.text is None :\n",
    "        Company.append(\"--\") \n",
    "    else:\n",
    "        Company.append(i.text)\n",
    "               \n",
    "#scraping the Skills_they_hire_for\n",
    "skills=driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\")[:48]\n",
    "for i in skills:\n",
    "    if i.text is None :\n",
    "        Skills_they_hire_for.append(\"--\") \n",
    "    else:\n",
    "        Skills_they_hire_for.append(i.text)\n",
    "        \n",
    "#scraping the Location\n",
    "loc=driver.find_elements_by_xpath(\"//small[@class='ellipsis']\")[:48]\n",
    "for i in loc:\n",
    "    if i.text is None :\n",
    "        Location.append(\"--\") \n",
    "    else:\n",
    "        Location.append(i.text)  \n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Designation\":Designation,\"Company\":Company,\"Skills_they_hire_for\":Skills_they_hire_for,\"Location\":Location})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_name</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Volumes_sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_name       Author_name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\"\n",
    "driver.get(url)\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping Books Name\n",
    "book=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in book:\n",
    "    if i.text is None :\n",
    "        Book_name.append(\"--\") \n",
    "    else:\n",
    "        Book_name.append(i.text)\n",
    "                \n",
    "# scraping Author name\n",
    "author=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in author:\n",
    "    if i.text is None :\n",
    "        Author_name.append(\"--\") \n",
    "    else:\n",
    "        Author_name.append(i.text)\n",
    "\n",
    "# scraping Volumes Sold\n",
    "volume=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in volume:\n",
    "    if i.text is None :\n",
    "        Volumes_sold.append(\"--\") \n",
    "    else:\n",
    "        Volumes_sold.append(i.text)\n",
    "                \n",
    "# scraping Publisher\n",
    "publisher=driver.find_elements_by_xpath(\"//td[@class='left']\")\n",
    "for i in publisher:\n",
    "    if i.text is None :\n",
    "        Publisher.append(\"--\") \n",
    "    else:\n",
    "        Publisher.append(i.text)\n",
    "               \n",
    "# scraping Genre\n",
    "genre = driver.find_elements_by_xpath((\"//td[@class='last left']\"))\n",
    "for i in genre:\n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\")\n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Book_name\":Book_name[1::5],\"Author_name\":Author_name[2::5],\"Volumes_sold\":Volumes_sold[3::5],\"Publisher\":Publisher[4::5],\"Genre\":Genre})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 9. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,845,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>883,655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>884,545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>265,774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>226,679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>171,435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>35,510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>194,745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time Ratings      Votes  \n",
       "0    57 min     9.2  1,845,677  \n",
       "1    51 min     8.7    883,655  \n",
       "2    44 min     8.2    884,545  \n",
       "3    60 min     7.6    265,774  \n",
       "4    43 min     7.6    226,679  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     44,968  \n",
       "96   50 min     7.8     55,660  \n",
       "97   42 min       8    171,435  \n",
       "98   45 min     7.1     35,510  \n",
       "99  572 min     8.6    194,745  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://www.imdb.com/list/ls095964455/\"\n",
    "driver.get(url)\n",
    "\n",
    "# creating empty lists for scraping data\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "# scraping top Movies name\n",
    "name = driver.find_elements_by_xpath((\"//h3[@class='lister-item-header']//a\"))\n",
    "for i in name:       \n",
    "    if i.text is None :\n",
    "        Name.append(\"--\") \n",
    "    else:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "#scraping year span       \n",
    "year = driver.find_elements_by_xpath((\"//span[@class='lister-item-year text-muted unbold']\"))\n",
    "for i in year:       \n",
    "    if i.text is None :\n",
    "        Year_span.append(\"--\") \n",
    "    else:\n",
    "        Year_span.append(i.text) \n",
    "        \n",
    "#scraping genre       \n",
    "gen = driver.find_elements_by_xpath((\"//span[@class='genre']\"))\n",
    "for i in gen :       \n",
    "    if i.text is None :\n",
    "        Genre.append(\"--\") \n",
    "    else:\n",
    "        Genre.append(i.text)\n",
    "        \n",
    "#scraping run time\n",
    "time = driver.find_elements_by_xpath((\"//span[@class='runtime']\"))\n",
    "for i in time:       \n",
    "    if i.text is None :\n",
    "        Run_time.append(\"--\") \n",
    "    else:\n",
    "        Run_time.append(i.text)\n",
    "\n",
    "#scraping ratings\n",
    "rate = driver.find_elements_by_xpath((\"//div[@class='ipl-rating-star small']\"))\n",
    "for i in rate:       \n",
    "    if i.text is None :\n",
    "        Ratings.append(\"--\") \n",
    "    else:\n",
    "        Ratings.append(i.text)\n",
    "\n",
    "#scraping votes\n",
    "vote = driver.find_elements_by_xpath((\"//span[@name='nv']\"))\n",
    "for i in vote:       \n",
    "    if i.text is None :\n",
    "        Votes.append(\"--\") \n",
    "    else:\n",
    "        Votes.append(i.text)\n",
    "\n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Name\":Name,\"Year_span\":Year_span,\"Genre\":Genre,\"Run_time\":Run_time,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 10. Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset_name      Data_type                  Task  \\\n",
       "0                             Abalone  Multivariate        Classification    \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "4                          Arrhythmia  Multivariate        Classification    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set  Multivariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "583                                       12684              23   2020   \n",
       "584                        Real              48             321   2020   \n",
       "585                        Real             731            1068   2021   \n",
       "586                        Real             731            1068   2021   \n",
       "587                        Real             557               5   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting to the web driver\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "\n",
    "#get the url\n",
    "url = \"https://archive.ics.uci.edu/\"\n",
    "driver.get(url)\n",
    "\n",
    "# clicking the 'View all dataset'\n",
    "view_dataset=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b\")\n",
    "view_dataset.click()\n",
    "\n",
    "#creating empty list for scraping data\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "# scraping Dataset_name\n",
    "dataset = driver.find_elements_by_xpath(\"//p[@class='normal']//b\")\n",
    "for i in dataset:       \n",
    "    if i.text is None :\n",
    "        Dataset_name.append(\"--\") \n",
    "    else:\n",
    "        Dataset_name.append(i.text)\n",
    "                \n",
    "# scraping Data_type\n",
    "datatype = driver.find_elements_by_xpath(\"//p[@class='normal']\")[:4125]\n",
    "for i in datatype:       \n",
    "    if i.text is None :\n",
    "        Data_type.append(\"--\") \n",
    "    else:\n",
    "        Data_type.append(i.text)\n",
    "               \n",
    "# scraping Task\n",
    "task = driver.find_elements_by_xpath(\"//p[@class='normal']\")\n",
    "for i in task:       \n",
    "    if i.text is None :\n",
    "        Task.append(\"--\") \n",
    "    else:\n",
    "        Task.append(i.text)\n",
    "                \n",
    "# scraping Attribute_type\n",
    "attribute_type = driver.find_elements_by_xpath(\"//p[@class='normal']\")\n",
    "for i in attribute_type:       \n",
    "    if i.text is None :\n",
    "        Attribute_type.append(\"--\") \n",
    "    else:\n",
    "        Attribute_type.append(i.text)\n",
    "                \n",
    "# scraping No_of_instances\n",
    "instances = driver.find_elements_by_xpath(\"//p[@class='normal']\")\n",
    "for i in instances:       \n",
    "    if i.text is None :\n",
    "        No_of_instances.append(\"--\") \n",
    "    else:\n",
    "        No_of_instances.append(i.text)\n",
    "              \n",
    "# scraping No_of_attribute\n",
    "attribute = driver.find_elements_by_xpath(\"//p[@class='normal']\")\n",
    "for i in attribute:\n",
    "    if i.text is None :\n",
    "        No_of_attribute.append(\"--\") \n",
    "    else:\n",
    "        No_of_attribute.append(i.text)\n",
    "        \n",
    "# scraping Year\n",
    "year = driver.find_elements_by_xpath(\"//p[@class='normal']\")\n",
    "for i in year:\n",
    "    if i.text is None :\n",
    "        Year.append(\"--\")\n",
    "    else:\n",
    "        Year.append(i.text)\n",
    "        \n",
    "# creating the dataframe from the scraped data\n",
    "df=pd.DataFrame({\"Dataset_name\":Dataset_name,\n",
    "                 \"Data_type\":Data_type[9::7],\n",
    "                 \"Task\":Task[10::7],\n",
    "                 \"Attribute_type\":Attribute_type[11::7],\n",
    "                 \"No_of_instances\":No_of_instances[12::7],\n",
    "                 \"No_of_attribute\":No_of_attribute[13::7],\n",
    "                 \"Year\":Year[14::7]})\n",
    "df         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
